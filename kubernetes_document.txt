What is kubernetes
==================
Kubernetes is an open-source container-orchestration system for automating computer application deployment, scaling, and management. It was originally designed by Google and is now maintained by the Cloud Native Computing Foundation. Wikipedia
Written in: Go
Developed by: Cloud Native Computing Foundation
Initial release: 7 June 2014; 6 years ago
Stable release: 1.18 / March 25, 2020; 3 months ago
License: Apache License 2.0
Original author: Google


why we use kubernets
====================


    Kubernetes is developed by Google whereas Docker Swarm is developed by Docker Inc.
    Kubernetes provides Auto-scaling whereas Docker Swarm doesnâ€™t support autoscaling.
    Kubernetes supports up to 5000 nodes whereas Docker Swarm supports more than 2000 nodes.
    Kubernetes is less extensive and customizable whereas Docker Swarm is more comprehensive and highly customizable.
    Kubernetes provides low fault tolerance while Docker provides high fault tolerance.

Key feature of kubernets
========================

    Offers automated scheduling
    Self-Healing capabilities
    Automated rollouts & rollback
    Horizontal Scaling & Load Balancing
    Provides a higher density of resource utilization
    Offers enterprise-ready features
    Application-centric management
    Auto-scalable infrastructure
    You can create predictable infrastructure
    Provides declarative configuration
    Deploy and update software at scale
    Offers environment consistency for development, testing, and production 


Key feature of coe (Kubernets orchestration engine)
===================================================

1. clustering

2. scheduling

3. scaling

4. load balancing

5. fault tolarance

6. app deployment

23.07.2020
----------
Kubernetes introduction
=======================

who need kubernets
------------------

1. developers

2. system admins

3. managers


Course Objectives
------------------
1. kubernetes- overview

2. containers - Docker

3. container orchestration	

4. Demo - setup kubernets

5. kubernets - concepts - pods |replicasets| Deployment | services

6. Networking in kubernets

7. Kubernets Management - kubctl

8. Kubernets Defintion files - YAML

9. Kubernets on cloud - aws/Gcp



container orchestration
=======================

container orchestration based on load it's scale up and down the container. Automatically deploying and managing container it's called container orchestration

Kubernets container orchestration technology

multiple technology available

1. Docker swarm from docker

2. kubernets from google

3. messos from apache 


when load increases kubernetes launch new instances 

when we run out of hardware scale up the number of nodes without down the application

24.07.2020
----------

kubernets Architecture
======================

1. Nodes

Nodes is a machine physical or virtual,  nodes is a worker machine thats why container launch by kubernets 

it's also called minions in the past 

2. cluster

cluster is set of nodes group together, if one node fail your application still accessible by another node 

3. Master 

Master responsible for managing cluster,  information of the cluster members stored in the master 

master is a another kubernets installed in it 


kubernets components
====================

1. api server
 
2. etcd service 

3. scheduler

4. controller

5. container runtime

6. kubctl (kublex service)




1. Api server 
access frontend of kubernets,  users, management devices, command line interfaces, all talk to api server to interact with kubernets

2. etcd 

distributed  reliable key value store used by kubernets to manage the cluster 

when you have multible nodes multible master etcd stored all nodes and cluster information in distributed manner

etcd responsible for implementing logs with in cluster ensure no conflix between master 

3. scheduler

scheduler responsible for distributing works across multible nodes it looks newly created container and assign them into nodes

4. controller 

controlled brain behind archestration noticing and responsible when nodes container or endpoints goes down 

controller make decision to bring up new container in such a cases

5. container runtime 

container runtime underline software in our case it's happened to be docker


6. kublet 

kublet is agent that run each node on the clutser, kublet make sure container running on nodes as expected 


master vs worker
===============

so far we see two types of server master and worker 

how does one serer as master another one as a slave 

worker node aslo known as minions as container hosted to run docker container need to runtime install 	

workernode -- cri-o

container runtime -- rkt


kube api server thats what makes master


worker node have kublet agent to interact with master

all the information and key value stored in the master -- etcd

master also has controll manager and scheduler 



kubctl kube command line tool 

kube controll tool used to deploy and manage on a kubernets cluster 

get cluster information get status of other node 

# kubctl run hello-minikube

kubctl run command used to deploy application


kubctl cluster-info

view information about cluster 

kubctl get nodes

list the nodes of kubernets cluster


27.07.2020
----------

kubernets setup
===============


we can setup kubernets local machine or virtual machine using minikube microk8s kubeadm   


kubeadm tool manage used to bootstrap production grade in the kubernets


cloud enviroment
================

Google cloud (Gcp)

Aws 

Microsoft azure



Devops websites
===============

https://kodekloud.com/courses


Minikube
========

This is easiest way to start kubernets on your local system


Master 
------

1. kube-apiserver

2. etcd

3. node-controller

4. replica controller


Worker node
-----------

1. kublet

2. container runtime



Minikube all of diffrent components into single image they configure singlenode kubernets cluster, we can get started in a matter of minutes

package into iso image available on online minikube provide executable commandline utility automatically download iso

you must install hybervisor on your system

finally you kubectl command line tool to interact with kubernets


you need three thing to run cluster 


1. hypervisor

2. kubctl

3. minikube



29.07.2020
=========

Minikube
========

Minikube is a tool that makes it easy to run Kubernetes locally. Minikube runs a single-node Kubernetes cluster inside a Virtual Machine (VM) on your laptop for users looking to try out Kubernetes or develop with it day-to-day


Minikube is an open source tool that enables you to run Kubernetes on your laptop or other local machine. It can work with Linux, Mac, and Windows operating systems. It runs a single-node cluster inside a virtual machine on your local machine


what is pod 
==========
Pods. Unlike other systems you may have used in the past, Kubernetes doesn't run containers directly; instead it wraps one or more containers into a higher-level structure called a pod. Any containers in the same pod will share the same resources and local network. ... Pods are used as the unit of replication in Kubernetes


A Pod is the basic execution unit of a Kubernetes application--the smallest and simplest unit in the Kubernetes object model that you create or deploy. A Pod represents processes running on your cluster. ... Pods in a Kubernetes cluster can be used in two main ways: Pods that run a single container.


A cluster consists of one master machine and multiple worker machines or nodes. The master coordinates between all the nodes. A pod is the smallest unit of a cluster. It represents a running process on a cluster.



01.08.2020
=========

kunernetes-concepts-pods
------------------------

Asssuption

Docker

kubernetes cluster


Application already devloped build and as docker image  available in docker repository like dockerhub

kubernetes can pullup from dockerhub and also kubernetes cluster setup done already

it single node setup or multinode setup 



kubernetes ultimate aim deploy application container on set of machines as worker node in a cluster 

kubernetes doesn't deploy container directly, container encabsulated into kubernetes object known as pod


pod is a single instance of application, pod is smallest object that you can create in kubernetes


kubernets incase load increses we create new pod in same node in singe node cluster


web application runs on two seperate pod in same node 


if load increases further node not sufficient to handle connection launch new pod in new node, new node should added in the cluster


pod have one to one relattionship with containers running with your application

to scale up create new pod to scale down delete existing pod


single pod can have mutible caontainers

helper container do some supporting task 

helper container alongside with your application container


when new applicaton created helper container also created, application dyes helper container also dyes


inside the pod two container can communicate each other using local network


how to deploy pods


$ kubectl run nginx --image nginx (image downloaded from dockerhub repository)

get list of pods in our cluster

$ kubectl get pods

10.08.2020
==========

what is yaml
============

YAML is a human-readable data-serialization language. It is commonly used for configuration files and in applications where data is being stored or transmitted. YAML targets many of the same communications applications as Extensible Markup Language but has a minimal syntax which intentionally differs from SGML.


yaml file used to represent data this case is a configuration data;

1.xml

2.json

3.yaml

yaml
----

key value fair we must follow space after colon

fruit: Banana

array/list

fruits
- banana
- orange
- apple

- represent array of element

dictionary

set of proerty group together under an item

you must have equal number of space before each item in the property

Number of spaces in each propery is key in the yaml file


we store diffrenet property of single object we use dictionary


apple: fruit


Dictionary are unordered collection

list are ordered collection

any line comes with # that will automatically ignored 


dictionary

banana:                           

  calories: .5
  fat: 5
  carbs: 2


banana:
  calories: .5
  carbs: 2
  fat: 5

list

fruits:

- orange
- apple
- mango


fruits:

- orange
- apple
- mango

# list of fruits  # commented out

fruits:

- orange
- apple
- mango


12.08.2020
==========

creating pod using yaml

Kubernetes uses yaml file as input

yaml input such as creation of pods replicasets service deployments 



kubernetes definition file contain four top level fields

pod-definition.yml

apiversion: 
kind:
metadata:

spec:


These are toplevel or root level properties you must have them in your configuration file

apiversion
----------

this is version of kubernetes using creating object 

depending on what we try to create we must use correct api version

since we woking on pod we set api version v1

kind
----

kind represent the type of object we going to create this case happend to be a pod

could be other possible values replicasets service deployments

Metadata
--------

metadata represent data about the object

first two specify in the string

metadata specify in the form of dictionary

labels:

we can easily filers the pods if we set labels before application deployments

reason for container list/array, pod have mulitiple container

- indicate this is first item in the list 


apiversion: v1 --- string
kind: pod      --- string
metadata:      ---- dictionary
  name: myapp-pod
  labels:
      app: myapp
      type: front-end

spec:
  containers:   ----- list/array
    - name: nginx-container
      image: nginx


once we create yaml file use below command to create pod

$ kubectl create -f pod-definition.yml

once we create pod how to summarize pod

$ kubectl get pods

$ kubectl describe pod myapp-pod
 


19.08.2020
=========

Kubernetes controller 
--------------------

controller brain behind kubernetes their process monitor kubernetes object response accordingly

Replication controller
---------------------

what is replica why do we need replication controller

Go back our scenario single pod running application  some reasons application crashes pod fail

user no longer able to access our appplication, to prevent user lost access our application, we would run more than one instance  or pod

that way if one fail still our application runs on another one	


replication controller helps to run multiple instance on single pod in the kubernetes cluster does providing high availability

Even if you have single pod, replication controller can help automatically bring up new pod when existing one fail


another reason we need replication controller create multiple pod to share the load

simple scenario single pod serving set of users, number of user increses we deploy additional pod 

demand further increases we worked out of resources, we could deploy additional pod  across the node

replication controller span across multiple nodes, in the cluster balance load across multiple pod 

scale our application when demand increases 


replication controller and replica set have same purpose but not the same  


replication controller is owner technology it's replaced by replica set 


replica set new recomented way to set replication

replication controller create multiple instances of pod


set replication controller
-------------------------

vim  rc-defintion.yml

apiVersion: v1
kind:ReplicationController
metadata:
  name: myapp-rc
  labels:
      app: myapp
      type: front-end

spec:
 - template:
     metadata:
       name: myapp-pod
       labels: 
         app: myapp
         type: front-end

     spec:
       containers:
       - name: nginx-container
         image: nginx
   
   replicas: 3


once file ready run below command


$ kubectl create -f rc-defintion.yml

replicationcontroller myapp-rc created

to view list of replication controller 

$ kubectl get replicationcontroller


to view list of pods


$ kubectl get pods


selector is major difference between replication controller and replicaset

replicaset
----------

vim  replicaset-defintion.yml

apiVersion: apps/v1
kind:ReplicaSet
metadata:
  name: myapp-replicaset
  labels:
      app: myapp
      type: front-end

spec:
 - template:
     metadata:
       name: myapp-pod
       labels: 
         app: myapp
         type: front-end

     spec:
       containers:
       - name: nginx-container
         image: nginx
   
   replicas: 3
   selectors:
      matchlabels:
         type: front-end



once finish yaml file run below command

$ kubectl create -f replicaset-definition.yml

view list of replicasets

$ kubectl get replicaset

$ kubectl get pods 




labels and selectors
--------------------

why labels and pods are objects in kubernetes

lets see one simple scenerio 

we we front end application as 3 pods

create replication controller or replicaset ensure 3 active pod running

using replicaset we can monitor existing pod

role of replicaset monitor the pods incase any of them fail 

how does replicaset knows what pod monitor

labeling in pod during creation comes handy to help replicaset which pod need to be monitor

now we provide labels as filter to replicaset


incase future any one pod fail replica need to create new pod, in this case we need template section



how we scale replicasets
-----------------------

we have 3 replicas in future we decided to scale upto 6	

first update number of replicas in the definition file

vim  rc-defintion.yml

apiVersion: apps/v1
kind:ReplicaSet
metadata:
  name: myapp-replicaset
  labels:
      app: myapp
      type: front-end

spec:
 - template:
     metadata:
       name: myapp-pod
       labels: 
         app: myapp
         type: front-end

     spec:
       containers:
       - name: nginx-container
         image: nginx
   
   replicas: 6
   selectors:
      matchlabels:
         type: front-end


$ kubectl replace -f replicaset-definition.yml

above command update the replicas upto 6

second way to do it 

$ kubectl scale --replicas=6 -f  replicaset-definition.yml


$ kubectl scale --replicas=6 -f replicaset myapp-replicaset


commands
-------

create replicaset 

$ kubectl create -f replicaset-definition.yml


view list of replicaset

$ kubectl get replicasets


delete replicaset

$ kubectl delete replicaset myapp-replicaset


update replicas use replace command

$ kubectl replace -f  replicaset-definition.yml


without modifying file we can update replicas

$ kubectl scale --replicas=6 -f replicaset-definition.yml




07.09.2020
==========

Kubernetes deployments
----------------------

. how you want deploy application in production enviroment

. for example you have web server deploy in production enviroment we need many enviroment 

. whenever newer version application build and available in docker registry like to upgrade docker instance seamlesly

. whenever upgrade instances you don't upgrade all of them at once this may impact user accessing our application 

. you might want to upgrade one after another that kind of upgrade known s rolling upgrade 

. suppose you perform upgarde result is error you ask to undo recent change like to rollback changes recently carried out

. you like to make multiple changes like undelying webserver as well as scaling your enviroments resource allocation etc

. you don't want apply each change imediatly you like to make pause enviroment and resume all changes rolledout together

. all of the capablities in kubernetes deployments

. each container in encabsulated as pod

. deployment is kubernetes object, deployment provide capablity upgrade undeline instances rolling update pause changes and resume changes 



how do we create deployment

. the content of deployment file exactly similar to replicat except kind

vim definition-deployment.yml

apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp-replicaset
  labels:
    app: myapp
spec:
  selector:
    matchLabels:
      app: myapp
  replicas: 3
   
  template:
    metadata:
      name: nginx-2
      labels:
        app: myapp
    spec:
      containers:
      - name: nginx 
        image: nginx    


once file completed 

$ kubectl create -f definition-deployment.yml


get deployments

$ kubectl get deployments

view replicasets

$ kubectl get replicasets

view pods

$ kubectl get pods

view full details of deployments

$ kubectl get all


03.10.2020
=========

Networking in kubernetes
------------------------

we have single node kubernetes cluster 

node has ip address 192.168.1.2 we use to access kubernetes node and ssh etc

if your using minikube setup we use minikube virtual machine ip address


single node kubernetes cluster we created single pod as we know pod hosted a container 

docker world ip address assigned to docker container 

kubernetes world ip address assined to pod

each pod in kubernetes has own internal ip address in this case ip assined to pod range 10.244.0.2 series 

so how we getting this ip address  when kubernetes initially configured we create internal private network 10.244.0.0


when we deploy multiple pod all get seperate ip address from the network 

accessing other pod using internal ip is not good idea subject to change when pod recreated 


important to understand how internal network works in kubernetes


how it's works when you have multible nodes in cluster


we have two nodes no part of cluster, pod deployed on two node they have own internal network

internal network not work when part of cluster 

kubernetes pod container communicate without nat 

kubernetes need network solution cisco aci network, clilium, flannel, nsx, calico


07.10.2020
==========

kubernetes services
------------------

. kubernetes services enable communication between various compontents within ouside of application

. kubernetes services us connect application together with other application or user

. our application has groups of pods 

. such as group for serving frontend 

. another group for serving backend process

. third group connecting external data source

. services enable connectivity to these groups of pods

. services made frontend available to end user

. it helps communication between backend and frontend pod 

. let's take a look one use case of services

.  let's start with external communication 

. we deployed our pod having web application running on it

. how external user access our application

.  kubernetes node has ip address 192.168.1.2 

. our labtab on same network 192.168.1.10 

. internal pod network range is 10.244.0.0

. pod has ip of 10.244.0.2

. clearly i can't ping or access pof from diffrent network

. from the node we can access kubernetes pod view the webpage

. from the my labtop i need access web application, how we done that so we need something in middle help us access application

. this where kubernetes service come into play

. service just a object like  pod replicaset deployment 

. one of his use case listen to port on node forward request on that port running the webapplication 

. this type of service known as nodeport service because service listen port on node forward request to pod



service types
-------------

1. nodeport

service makes interal pod is accessible 

2. cluster ip

this case cluster create virtual ip inside the cluster enable services between diffrent services such as frontend application backend db

3. loadbalancer

distribute the load to appropriate webappication in frontend tier


nodeport kubernetes service
--------------------------

. service can help mapping port on node to port on pod

. port1 on is actual webserver running in 80 refered to target port

. port2 in service port is simply refered as port

. service like a virtual server inside a node it has own ip address that's cluster ip address 

. finally we hvae port node itself nodeport valid range 30000 to 32767



crete sevice-definition.yaml file

vim sevice-definition.yaml

apiVersion: v1
kind: service
metadata: 
  name: myapp-service

spec:
    type: Nodeport
    ports:
     - targetport: 80
       port: 80
       nodeport: 30008
    selector:
      app: myapp
      type: frontend
       

create service
-------------

$ kubectl create -f  sevice-definition.yaml


view created services

$ kubectl get services

now access the service using curl


curl http://192.168.1.2:30008



. what you do when you have multiple pod

. in production enviroment you have multiple instances for high availability and load balancing purposes

. we same labels during create the service

. when service created looks for matching pod 

. then service automatically select pod to forward external request

. you don't have to do anyadditional configuration 

. random algorithm used to balance the load

. pod running on different node service automatically map to nodeport we can access using same nodeip and port



            





 











 


    




  	
















   


   
 








  

 





















 	



	






